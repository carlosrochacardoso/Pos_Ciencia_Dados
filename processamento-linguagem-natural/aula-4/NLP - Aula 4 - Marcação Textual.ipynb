{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP - Aula 4 - Marcação Textual.ipynb","version":"0.3.2","provenance":[{"file_id":"1IhnRmXgoK1w1KgOFMSAWrIJK2LhNS9BN","timestamp":1562259070302}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"k6qowYBNz7c9","colab_type":"text"},"source":["NLP - Aula 4 - Marcação Textual\n","===============\n","\n","Nesta aula prática iremos testar as bibliotecas disponiveis em Python para realizar as principais tarefas de marcação textual.\n","\n","\n","## Bibilotecas POS_TAG, MAC_MORPHO, ##\n","\n","Vamos testar algumas dessas bibliotecas e observar como elas taguearam as palavras para o português.\n","\n","\n","### NLTK.POS_TAG\n","\n","O POS-tagger, processa uma sequência de palavras e adiciona em cada palavra qual parte do discurso ela pertence. Testem a função *nltk.pos_tag(text)*\n"]},{"cell_type":"code","metadata":{"id":"IO87aS2d038z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VXGO5Sn11pJO","colab_type":"text"},"source":["### MAC_MORPHO###\n","\n","Vamos testar a biblioteca Mac-Mopho, suas palavras e sentenças tagueadas: *nltk.corpus.mac_morpho.tagged_words()* e *nltk.corpus.mac_morpho.tagged_sents ()*"]},{"cell_type":"code","metadata":{"id":"vNOTTjYA1vAf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wkn2hStuD8d2","colab_type":"text"},"source":["## Modelos n-gram ##\n","\n","\n","O diretor de marketing de mecanismos de busca da *DataSciencester* deseja criar milhares de páginas da Web sobre ciência de dados para que seu site tenha uma classificação mais alta nos resultados de pesquisa para termos relacionados à ciência de dados. (Você tenta explicar a ela que os algoritmos dos mecanismos de pesquisa são inteligentes o suficiente para que isso não funcione, mas ele se recusa a ouvir.)\n","\n","Claro, ele não quer escrever milhares de páginas da web, nem quer pagar uma horda de \"estrategistas de conteúdo\" para fazê-lo. Em vez disso, ele pergunta se você pode de alguma forma gerar programaticamente essas páginas da web. Para fazer isso, precisaremos de um jeito de modelar a linguagem.\n","\n","Uma abordagem é começar com um corpus de documentos e aprender um modelo estatístico de linguagem. No nosso caso, começaremos com o ensaio de Mike Loukides, [\"O que é ciência de dados?\"](https://www.oreilly.com/ideas/what-is-data-science)\n","\n","Usaremos solicitações e BeautifulSoup para recuperar os dados. Há um par de questões que merecem atenção.\n","\n","A primeira é que os apóstrofos no texto são, na verdade, o caractere Unicode `u\"\\u2019\"`. Vamos criar uma função auxiliar para substituí-los por apóstrofos normais:"]},{"cell_type":"code","metadata":{"id":"_d2y27XPFniI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlgqC-j1ENdZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S2CSy39MEVA7","colab_type":"text"},"source":["A segunda questão é que, assim que recebermos o texto da página da web, queremos dividi-la em uma sequência de palavras e pontos (para que possamos saber onde as frases terminam). Podemos fazer isso usando re.findall():"]},{"cell_type":"code","metadata":{"id":"AY7r_isZEWSE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RruYng2-FOqk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H5djbf7pEb9Z","colab_type":"text"},"source":["Nós certamente poderíamos (e provavelmente deveríamos) limpar esses dados ainda mais. Ainda há alguma quantidade de texto estranho no documento (por exemplo, a primeira palavra é \"We've\") e dividimos as frases a partir de pontos que não são, na verdade, pontos finais (por exemplo, em \"Web 2.0\"), e há um punhado de legendas e listas por toda parte. Dito isso, trabalharemos com o documento como ele é.\n","\n","Agora que temos o texto como uma sequência de palavras, podemos modelar a linguagem da seguinte maneira: dada uma palavra inicial (digamos, \"web\"), olhamos todas as palavras que a seguem nos documentos de origem (aqui \"2\", \"is\", \"front\", \"was\", \"server\", \"has\", \"friend\", \"services\" etc). Nós escolhemos aleatoriamente uma dessas para ser a próxima palavra, e repetimos o processo até chegarmos a um ponto, que significa o fim da frase. Chamamos isso de *modelo bigrama*, como é determinado completamente pelas freqüências dos bigramas (pares de palavras) nos dados originais.\n","\n","Que tal uma palavra inicial? Podemos escolher aleatoriamente de palavras que seguem um ponto. Para começar, vamos precomputar as possíveis transições de palavras. Lembre-se de que o `zip` para quando qualquer uma de suas entradas terminar, de modo que `zip(document, document[1:])` fornece precisamente os pares de elementos consecutivos do documento:"]},{"cell_type":"code","metadata":{"id":"2O_C4QPUEddY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wx87EVUSEhA1","colab_type":"text"},"source":["Agora estamos prontos para gerar sentenças:"]},{"cell_type":"code","metadata":{"id":"sAW2Nnj1EiIe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4OLqqAjIElyz","colab_type":"text"},"source":["As frases produzidas são sem sentido, mas são o tipo de tagarelice que você pode colocar no seu site se estiver tentando soar como se fosse um site de ciência dos dados. Por exemplo:"]},{"cell_type":"code","metadata":{"id":"xc0snk60Eqqo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iS-nHfpdErUu","colab_type":"text"},"source":["Podemos tornar as frases menos sem sentido, olhando para trigramas, triplas de palavras consecutivas. (Em geral, você pode ver n-gramas consistindo de n palavras consecutivas, mas três serão suficientes para nós.) Agora as transições dependerão das duas palavras anteriores:"]},{"cell_type":"code","metadata":{"id":"ccs_NaqFEvFv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T3ynw9awEvc3","colab_type":"text"},"source":["Observe que agora temos que rastrear as palavras iniciais separadamente. Podemos gerar sentenças praticamente da mesma maneira:"]},{"cell_type":"code","metadata":{"id":"Ihz3Qb8YE9lH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LCFMmDaBFB_a","colab_type":"text"},"source":["Essa função vai produzir sentenças como:"]},{"cell_type":"code","metadata":{"id":"ONUrUPvDFFbX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o8H5sJbMFFrH","colab_type":"text"},"source":["Claro, elas soam melhor porque a cada passo o processo de geração tem menos escolhas, e em muitos passos há apenas uma única escolha. Isso significa que você freqüentemente gerará frases (ou pelo menos frases longas) que foram vistas literalmente nos dados originais. Ter mais dados ajudaria; também funcionaria melhor se você coletasse *n-gramas* de vários ensaios sobre ciência de dados."]}]}