{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0tT0tbVhLC6"
   },
   "source": [
    "**NLP - Aula 3 - Similaridade Textual**\n",
    "===============================\n",
    "\n",
    "Durante a prática de hoje vamos testar alguns dos conceitos que vimos na aula teórica sobre similaridade textual\n",
    "\n",
    "## Similaridade de Jaccard ##\n",
    "\n",
    "Vamos realizar o teste criando o algoritmo a partir da fórmula apresentada na aula J(X,Y) = |X∩Y| / |X∪Y| e um exemplo com a biblioteca __nltk.metrics.distance__\n",
    "\n",
    "Comparem as duas frases exemplo:\n",
    "\n",
    "\n",
    "*   AI is our friend and it has been friendly\n",
    "*   AI and humans have always been friendly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 688,
     "status": "ok",
     "timestamp": 1561834615885,
     "user": {
      "displayName": "Keyla Macharet",
      "photoUrl": "https://lh5.googleusercontent.com/-_8tYhr4aAjo/AAAAAAAAAAI/AAAAAAAAEFk/XECa1Knjsbc/s64/photo.jpg",
      "userId": "10107990486249420180"
     },
     "user_tz": 180
    },
    "id": "pj-4L7dQhJi9",
    "outputId": "3eb558e2-b921-4ee5-dee0-58781a037d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Inclua aqui o seu próprio algoritmo para calcular a distância de Jaccard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1561834774672,
     "user": {
      "displayName": "Keyla Macharet",
      "photoUrl": "https://lh5.googleusercontent.com/-_8tYhr4aAjo/AAAAAAAAAAI/AAAAAAAAEFk/XECa1Knjsbc/s64/photo.jpg",
      "userId": "10107990486249420180"
     },
     "user_tz": 180
    },
    "id": "XJi02kCHji-0",
    "outputId": "1fd8a1be-be34-428c-f69e-2832f0c35d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#Inclua aqui o resultado utilizando a biblioteca já criada\n",
    "\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UWjVqI5Fq_Ew"
   },
   "source": [
    "## Plágio de texto\n",
    "\n",
    "Através do cálculo da similaridade do Cosseno, com abordagem TFIDF + Bag of Words, iremos comparar 5 artigos de notícias e observarmos o percentual de similaridade que eles tem entre si e com base nisso analisarmos se houve cópia de uma notícia entre um site ou outro.\n",
    "\n",
    "A mesma abordagem poderia ser utilizada para várias outras aplicações de plágio, tais como a originalidade de um artigo, cópias entre exercícios de alunos, etc.\n",
    "\n",
    "As urls dos artigos que iremos analisar são:\n",
    "\n",
    "*  https://drive.google.com/uc?export=download&id=191Ae2usY5cEAPJvgxKpIve6Is1sqf5Lh\n",
    "*  https://drive.google.com/uc?export=download&id=1oIbaR3uYZajpFfOQlY2-Jfs_pik-YfxY\n",
    "*  https://drive.google.com/uc?export=download&id=1vSzS0ZwxN2KQjOZo4QgIIVsgtEbhtmXQ\n",
    "*  https://drive.google.com/uc?export=download&id=1Xou8jQIOk7GomEFtZmqcII_6vyiPo4Di\n",
    "*  https://drive.google.com/uc?export=download&id=1U1Le1LWAQbrclqL-oIt65T9PtXsqW1hN\n",
    "\n",
    "\n",
    "Primeira parte do nosso código será a importação de todas as bibliotecas que iremos utilizar:\n",
    "\n",
    "Para funções gerais de limpeza e tokenização\n",
    "*  NLTK\n",
    "*  string\n",
    "\n",
    "Para a leitura do conteúdo _raw_ das urls dos artigos\n",
    "*  requests\n",
    "\n",
    "Para calcular TF-IDF e a similaridade do cosseno\n",
    "*  from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "*  from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1561914144784,
     "user": {
      "displayName": "Keyla Macharet",
      "photoUrl": "https://lh5.googleusercontent.com/-_8tYhr4aAjo/AAAAAAAAAAI/AAAAAAAAEFk/XECa1Knjsbc/s64/photo.jpg",
      "userId": "10107990486249420180"
     },
     "user_tz": 180
    },
    "id": "pe5gEpNG89Dn",
    "outputId": "6afe4757-7665-48eb-cd32-5b14b0e743b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IYtmtUip9J95"
   },
   "source": [
    "### Recuperação e tratamento dos textos ###\n",
    "\n",
    "Como primeira parte do nosso desenvolvimento criaremos uma função com o nome **RetrieveAndProcessNews** que vai recuperar os conteúdos dos artigos e tratar os textos com os seguintes pré-processamentos:\n",
    "*  Tokenizar as palavras\n",
    "*  Remover stopwords\n",
    "*  Executar o processo de steeming (PorterStemmer)\n",
    "*  Remover pontuação\n",
    "*  Converter o texto para letras minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04Rszmur3H_5"
   },
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-FwVk0xp9IUv"
   },
   "source": [
    "\n",
    "## TF-IDF e Similaridade do Cosseno ##\n",
    "\n",
    "Vamos criar uma função para calcular TF-IDF e em seguida a função para calcular a similaridade do cosseno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsKQxxrEPway"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aacNLawiYdzx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifRNeQOxPvYE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iy2w9xPwS9OL"
   },
   "source": [
    "##  Hora de criar a função Main ##\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1993,
     "status": "error",
     "timestamp": 1561916375268,
     "user": {
      "displayName": "Keyla Macharet",
      "photoUrl": "https://lh5.googleusercontent.com/-_8tYhr4aAjo/AAAAAAAAAAI/AAAAAAAAEFk/XECa1Knjsbc/s64/photo.jpg",
      "userId": "10107990486249420180"
     },
     "user_tz": 180
    },
    "id": "8h-okTL0TSyp",
    "outputId": "ecc8aa3e-2471-4fa4-846a-1abe83e38bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "========COSINE SIMILARITY=============================\n",
      "\n",
      "                   File1   File2   File3   File4   File5   \n",
      "File1   "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-1192aa167714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#PrintTFIDF(tfs_Term, tfs_Values, ['File1', 'File2', 'File3', 'File4', 'File5'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mCalculateAndPrintCosineSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfs_Values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'File1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'File2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'File3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'File4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'File5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-3b57be1686a4>\u001b[0m in \u001b[0;36mCalculateAndPrintCosineSimilarity\u001b[0;34m(tfsValues, fileNames)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileNames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'   '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumFiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mmatrixValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfsValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfsValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mnumValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrixValue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileNames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m--> 112\u001b[0;31m                         estimator=estimator)\n\u001b[0m\u001b[1;32m    113\u001b[0m         Y = check_array(Y, accept_sparse='csr', dtype=dtype,\n\u001b[1;32m    114\u001b[0m                         estimator=estimator)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.06010336 0.         0.03005168 0.         0.03005168 0.\n 0.         0.0362029  0.03005168 0.         0.03005168 0.04487256\n 0.03005168 0.04487256 0.03005168 0.         0.         0.\n 0.         0.         0.03005168 0.03005168 0.0724058  0.03005168\n 0.         0.03005168 0.         0.         0.         0.0362029\n 0.         0.04487256 0.04487256 0.06010336 0.         0.\n 0.         0.         0.05056084 0.04487256 0.04487256 0.05056084\n 0.03005168 0.03005168 0.         0.03005168 0.0362029  0.02138202\n 0.         0.         0.0724058  0.03005168 0.04487256 0.09015503\n 0.04487256 0.         0.         0.         0.         0.\n 0.06010336 0.         0.         0.03005168 0.04487256 0.\n 0.         0.04487256 0.         0.         0.         0.\n 0.         0.         0.04487256 0.04487256 0.03005168 0.\n 0.03005168 0.         0.17696293 0.04487256 0.         0.\n 0.0362029  0.         0.         0.         0.         0.08974513\n 0.1264021  0.04487256 0.         0.03005168 0.03005168 0.03005168\n 0.         0.         0.         0.         0.         0.\n 0.04487256 0.04487256 0.         0.04487256 0.         0.08974513\n 0.         0.         0.06010336 0.05056084 0.         0.03005168\n 0.         0.         0.         0.         0.05056084 0.04487256\n 0.0724058  0.03005168 0.30336503 0.         0.         0.04487256\n 0.         0.         0.         0.         0.08974513 0.\n 0.         0.06010336 0.02528042 0.04487256 0.03005168 0.03005168\n 0.         0.         0.         0.04487256 0.06414605 0.\n 0.         0.         0.06010336 0.         0.03005168 0.03005168\n 0.0724058  0.         0.         0.         0.17696293 0.21036175\n 0.03005168 0.         0.         0.04487256 0.         0.04487256\n 0.06010336 0.03005168 0.         0.04487256 0.03005168 0.\n 0.         0.06010336 0.         0.         0.         0.03005168\n 0.04487256 0.04487256 0.09015503 0.         0.         0.\n 0.         0.04487256 0.02138202 0.         0.03005168 0.03005168\n 0.04487256 0.03005168 0.30051678 0.         0.03005168 0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.03005168 0.         0.\n 0.02528042 0.0362029  0.06010336 0.04487256 0.         0.03005168\n 0.03005168 0.         0.04487256 0.04487256 0.         0.\n 0.03005168 0.         0.04487256 0.0362029  0.05056084 0.\n 0.         0.03005168 0.06010336 0.         0.         0.\n 0.05056084 0.         0.04487256 0.03005168 0.03005168 0.\n 0.         0.04487256 0.         0.04487256 0.         0.0362029\n 0.         0.         0.02528042 0.04487256 0.         0.\n 0.         0.04487256 0.         0.03005168 0.0362029  0.\n 0.         0.04487256 0.         0.         0.09015503 0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.04487256 0.         0.         0.         0.\n 0.03005168 0.         0.14967412 0.         0.         0.0724058\n 0.         0.         0.09015503 0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.04487256 0.         0.         0.03005168 0.\n 0.         0.         0.         0.         0.         0.0362029\n 0.02528042 0.         0.         0.         0.0362029  0.02138202\n 0.04487256 0.04487256 0.         0.         0.02528042 0.02528042\n 0.03005168 0.         0.         0.         0.         0.\n 0.04487256 0.02138202 0.         0.02528042 0.04487256 0.04487256\n 0.02528042 0.         0.         0.03005168 0.03005168 0.\n 0.         0.09015503 0.         0.05056084 0.02528042 0.\n 0.         0.12020671 0.         0.         0.         0.\n 0.04487256 0.         0.06010336 0.         0.         0.03005168\n 0.03005168 0.08974513 0.02528042 0.06010336 0.08974513 0.\n 0.1086087  0.         0.         0.         0.03005168 0.\n 0.         0.02138202 0.07584126 0.         0.         0.02528042\n 0.         0.06010336 0.03005168 0.03005168 0.03005168 0.07584126\n 0.05056084 0.09015503 0.03005168 0.09015503 0.05056084 0.\n 0.06010336 0.         0.         0.         0.         0.03005168\n 0.04487256 0.         0.17105613 0.         0.         0.\n 0.         0.04487256 0.         0.         0.03005168 0.\n 0.02528042 0.         0.03005168 0.03005168 0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.06010336 0.0362029  0.         0.\n 0.07584126 0.         0.         0.         0.         0.02528042\n 0.         0.03005168 0.03005168 0.0362029  0.         0.04487256\n 0.04487256 0.         0.         0.0362029  0.         0.19243815\n 0.         0.         0.         0.         0.04487256 0.\n 0.         0.         0.         0.0362029  0.03005168 0.04487256\n 0.         0.         0.         0.         0.0362029  0.\n 0.06010336 0.21036175 0.         0.         0.         0.03005168\n 0.         0.         0.04487256 0.         0.         0.\n 0.         0.04487256 0.03005168 0.08974513 0.         0.\n 0.         0.         0.03005168 0.         0.         0.\n 0.07584126 0.         0.         0.         0.03005168 0.03005168\n 0.03005168 0.         0.         0.         0.         0.\n 0.         0.03005168 0.04487256 0.06010336 0.         0.\n 0.05056084 0.02528042 0.         0.04487256 0.02528042 0.\n 0.08552807 0.         0.         0.         0.         0.04487256\n 0.0362029  0.         0.08974513 0.         0.03005168 0.\n 0.         0.         0.         0.         0.         0.03005168\n 0.06010336 0.         0.         0.         0.         0.03005168\n 0.         0.         0.         0.         0.04487256 0.\n 0.04487256 0.         0.         0.08974513 0.03005168 0.0362029\n 0.         0.03005168 0.         0.0362029  0.         0.02528042\n 0.         0.03005168 0.03005168 0.         0.02528042 0.\n 0.         0.         0.14967412 0.         0.03005168 0.1282921\n 0.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP - Aula 3 - Similaridade Textual - Resposta.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
